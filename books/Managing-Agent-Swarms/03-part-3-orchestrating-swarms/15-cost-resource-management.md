# Chapter 15: Cost and Resource Management

Elena Rodriguez watched the billing dashboard with growing concern. Her swarm of 40 agents had been working on the inventory management system for five days. The AWS bill showed $8,347 in compute costs. The OpenAI API charges added another $2,156. Total: $10,503.

For five days of work.

Her engineering team could have built the same system in three weeks for about $15,000 in salary costs (one senior engineer, one mid-level engineer). The swarm was faster but not cheaper—and they were only halfway done.

The math was sobering:
- 40 agents × $0.03/1K tokens (GPT-4) × average 500 tokens per agent action × 2,000 actions per day = $1,200/day in API costs alone
- EC2 instances for agent orchestration: $400/day
- Database operations, storage, bandwidth: $200/day
- Total burn rate: $1,800/day

At this rate, a two-week sprint would cost over $25,000. That's economically viable for a critical project with tight deadlines, but not sustainable for routine development work.

This is the harsh reality of swarm-based development: **Compute is expensive. Running dozens of AI agents simultaneously burns money fast. If you're not careful, your swarm will produce fantastic code at unsustainable cost.**

The challenge isn't just reducing cost—it's optimizing for cost-effectiveness. Sometimes spending more money is worth it. Sometimes it's wasteful. Knowing the difference is critical.

## The Economics of Swarm Development

Let's start with the fundamental economics. What actually costs money when running a swarm?

### Cost Components

**1. LLM API Costs (Typically 60-70% of total)**

Every agent action involves API calls:
- Input tokens: Code, context, instructions sent to the LLM
- Output tokens: Code, decisions, explanations generated by the LLM

```python
# Typical agent action costs
def estimate_action_cost(agent_action, model='gpt-4'):
    pricing = {
        'gpt-4': {'input': 0.03, 'output': 0.06},  # per 1K tokens
        'gpt-4-turbo': {'input': 0.01, 'output': 0.03},
        'gpt-3.5-turbo': {'input': 0.001, 'output': 0.002},
        'claude-3-opus': {'input': 0.015, 'output': 0.075},
        'claude-3-sonnet': {'input': 0.003, 'output': 0.015},
    }

    input_tokens = agent_action.context_size + agent_action.instruction_size
    output_tokens = agent_action.response_size

    input_cost = (input_tokens / 1000) * pricing[model]['input']
    output_cost = (output_tokens / 1000) * pricing[model]['output']

    return input_cost + output_cost

# Example: Agent reviews a 500-line file and generates 200-line change
action_cost = estimate_action_cost(
    AgentAction(
        context_size=4000,    # 500 lines × ~8 tokens/line
        instruction_size=500,  # Task description
        response_size=2000     # 200 lines × ~10 tokens/line
    ),
    model='gpt-4'
)
# Cost: (4500/1000 * 0.03) + (2000/1000 * 0.06) = $0.135 + $0.12 = $0.255 per action
```

With 40 agents each performing 50 actions/day:
- 40 agents × 50 actions/day × $0.255/action = $510/day
- Over two weeks: $7,140

**2. Compute Infrastructure (20-30% of total)**

Agents need somewhere to run:
- Orchestration servers (coordinate agent activity)
- Database servers (store code, state, metrics)
- Job queue servers (manage task distribution)
- Monitoring infrastructure

```python
# Infrastructure cost estimation
def estimate_infrastructure_cost():
    costs = {
        'orchestration': {
            'instances': 2,
            'type': 'c5.2xlarge',  # 8 vCPU, 16 GB RAM
            'hourly_rate': 0.34,
            'hours_per_day': 24
        },
        'database': {
            'instances': 1,
            'type': 'db.r5.xlarge',  # 4 vCPU, 32 GB RAM
            'hourly_rate': 0.50,
            'hours_per_day': 24
        },
        'queue': {
            'instances': 1,
            'type': 't3.large',  # 2 vCPU, 8 GB RAM
            'hourly_rate': 0.083,
            'hours_per_day': 24
        },
        'storage': {
            'gb_per_day': 100,
            'rate_per_gb_month': 0.10,
            'days_per_month': 30
        },
        'bandwidth': {
            'gb_per_day': 50,
            'rate_per_gb': 0.09
        }
    }

    daily_cost = 0
    for component, config in costs.items():
        if component in ['orchestration', 'database', 'queue']:
            daily_cost += config['instances'] * config['hourly_rate'] * config['hours_per_day']
        elif component == 'storage':
            daily_cost += (config['gb_per_day'] * config['rate_per_gb_month']) / config['days_per_month']
        elif component == 'bandwidth':
            daily_cost += config['gb_per_day'] * config['rate_per_gb']

    return daily_cost

# Result: ~$25/day in infrastructure
```

**3. Storage and Data Transfer (5-10% of total)**

- Code repositories
- Agent state and history
- Metrics and logs
- Test artifacts
- Data transfer between services

**4. Testing and CI/CD (5-10% of total)**

- Test execution compute
- CI/CD pipeline runs
- Deployment infrastructure

### Total Cost Model

```python
def total_swarm_cost(num_agents, days, model='gpt-4', actions_per_agent_per_day=50):
    # LLM costs
    cost_per_action = estimate_action_cost(
        AgentAction(context_size=4000, instruction_size=500, response_size=2000),
        model=model
    )
    llm_cost = num_agents * actions_per_agent_per_day * cost_per_action * days

    # Infrastructure
    infrastructure_cost_per_day = estimate_infrastructure_cost()
    infrastructure_cost = infrastructure_cost_per_day * days

    # Testing/CI (estimate 10% of infrastructure)
    testing_cost = infrastructure_cost * 0.10

    return {
        'llm': llm_cost,
        'infrastructure': infrastructure_cost,
        'testing': testing_cost,
        'total': llm_cost + infrastructure_cost + testing_cost
    }

# 40 agents, 14 days, GPT-4
cost = total_swarm_cost(40, 14, 'gpt-4')
print(f"Total cost: ${cost['total']:,.2f}")
# Output: Total cost: $7,840.00

# Compare with cheaper model
cost_turbo = total_swarm_cost(40, 14, 'gpt-4-turbo')
print(f"Total cost (GPT-4 Turbo): ${cost_turbo['total']:,.2f}")
# Output: Total cost (GPT-4 Turbo): $3,190.00

# Savings: $4,650 (59% reduction)
```

## Cost Optimization Strategies

Now that we understand costs, how do we reduce them without sacrificing quality?

### Strategy 1: Model Selection and Mixing

Not every task requires GPT-4. Use cheaper models for simpler tasks.

```python
def select_model_for_task(task):
    """
    Choose the appropriate model based on task complexity.
    """
    complexity_indicators = {
        'high': [
            'architectural_design',
            'complex_algorithm',
            'security_critical',
            'performance_optimization',
            'novel_problem'
        ],
        'medium': [
            'business_logic',
            'api_integration',
            'refactoring',
            'bug_investigation'
        ],
        'low': [
            'code_formatting',
            'simple_tests',
            'documentation',
            'config_updates',
            'routine_refactoring'
        ]
    }

    # Determine task complexity
    if task.type in complexity_indicators['high']:
        return 'gpt-4'  # $0.03/$0.06 per 1K tokens
    elif task.type in complexity_indicators['medium']:
        return 'gpt-4-turbo'  # $0.01/$0.03 per 1K tokens
    else:
        return 'gpt-3.5-turbo'  # $0.001/$0.002 per 1K tokens
```

**Example task distribution for building an e-commerce platform:**

- High complexity (GPT-4): 20% of tasks
  - Payment processing architecture
  - Security implementation
  - Performance optimization
  - Complex business rules

- Medium complexity (GPT-4 Turbo): 50% of tasks
  - Product catalog API
  - Order management
  - User authentication
  - Search functionality

- Low complexity (GPT-3.5 Turbo): 30% of tasks
  - Test generation
  - Documentation
  - Code formatting
  - Configuration files

**Cost impact:**

```python
# All GPT-4
all_gpt4_cost = total_swarm_cost(40, 14, 'gpt-4')
# $7,840

# Mixed models (20% GPT-4, 50% GPT-4 Turbo, 30% GPT-3.5)
mixed_cost = (
    total_swarm_cost(8, 14, 'gpt-4')['total'] +
    total_swarm_cost(20, 14, 'gpt-4-turbo')['total'] +
    total_swarm_cost(12, 14, 'gpt-3.5-turbo')['total']
)
# $3,947

# Savings: $3,893 (50% reduction)
```

### Strategy 2: Context Window Optimization

Every token sent to the LLM costs money. Minimize context without losing necessary information.

```python
class ContextOptimizer:
    def optimize_context(self, task, full_context):
        """
        Reduce context size while preserving essential information.
        """
        essential_context = []

        # 1. Task-relevant files only
        relevant_files = self.identify_relevant_files(task, full_context.files)
        essential_context.extend(relevant_files)

        # 2. Summarize large files instead of including full content
        for file in relevant_files:
            if file.line_count > 500:
                file.content = self.summarize_file(file)

        # 3. Include only recent history, not entire conversation
        essential_context.append(full_context.recent_history(last_n=5))

        # 4. Compress repeated patterns
        essential_context = self.compress_patterns(essential_context)

        return essential_context

    def identify_relevant_files(self, task, all_files):
        """
        Use static analysis to identify files that task likely needs.
        """
        relevant = []

        # Files mentioned in task description
        mentioned_files = extract_file_references(task.description)
        relevant.extend(mentioned_files)

        # Files that import/use mentioned files
        for file in mentioned_files:
            dependencies = find_dependencies(file)
            relevant.extend(dependencies)

        return list(set(relevant))  # Deduplicate
```

**Example: Refactoring a payment processing function**

Without optimization:
- Full codebase: 50 files, 200K tokens
- Cost per agent action: (200K/1000) × $0.03 = $6.00

With optimization:
- Payment processing file: 500 lines
- Direct dependencies: 3 files, 800 lines
- Type definitions: 200 lines
- Total: 1,500 lines ≈ 12K tokens
- Cost per agent action: (12K/1000) × $0.03 = $0.36

Savings: $5.64 per action (94% reduction)

For 40 agents × 50 actions/day × 14 days = 28,000 actions:
- Without optimization: $168,000
- With optimization: $10,080
- Savings: $157,920

### Strategy 3: Lazy Evaluation and Caching

Don't recompute what you've already computed.

```python
class AgentCache:
    def __init__(self):
        self.response_cache = {}
        self.code_analysis_cache = {}

    def get_cached_response(self, task_hash, context_hash):
        """
        Return cached response if task and context match a previous request.
        """
        cache_key = f"{task_hash}:{context_hash}"
        return self.response_cache.get(cache_key)

    def cache_response(self, task_hash, context_hash, response):
        """
        Store response for future reuse.
        """
        cache_key = f"{task_hash}:{context_hash}"
        self.response_cache[cache_key] = response

    def analyze_code_cached(self, file_path, file_hash):
        """
        Analyze code structure, but cache results by file hash.
        """
        if file_hash in self.code_analysis_cache:
            return self.code_analysis_cache[file_hash]

        # Expensive analysis
        analysis = perform_static_analysis(file_path)

        self.code_analysis_cache[file_hash] = analysis
        return analysis
```

**Cache hit rates:**

- Code analysis: ~70% hit rate (same files analyzed repeatedly)
- Common refactorings: ~40% hit rate (similar patterns in different files)
- Test generation: ~30% hit rate (similar test structures)

**Cost impact:**

Without caching: 28,000 actions × $0.255/action = $7,140
With caching (40% reduction): 16,800 actions × $0.255/action = $4,284
Savings: $2,856 (40% reduction)

### Strategy 4: Swarm Size Optimization

More agents isn't always better. Find the optimal swarm size for your problem.

```python
def optimize_swarm_size(project_complexity, deadline_days, budget):
    """
    Determine optimal number of agents given constraints.
    """
    # Model: Productivity increases with swarm size but with diminishing returns
    # due to coordination overhead

    def productivity(num_agents):
        """
        Productivity = num_agents × efficiency_factor
        Efficiency decreases with swarm size due to coordination overhead.
        """
        if num_agents <= 10:
            efficiency = 0.95
        elif num_agents <= 30:
            efficiency = 0.80
        elif num_agents <= 50:
            efficiency = 0.65
        else:
            efficiency = 0.50

        return num_agents * efficiency

    def cost(num_agents, days):
        return total_swarm_cost(num_agents, days, model='gpt-4')['total']

    def time_to_complete(num_agents, complexity):
        """
        Estimate days to complete based on swarm productivity.
        """
        effective_agents = productivity(num_agents)
        # Assume complexity is measured in "agent-days"
        return complexity / effective_agents

    # Find optimal swarm size
    best_size = None
    best_score = float('-inf')

    for num_agents in range(5, 101, 5):
        days_needed = time_to_complete(num_agents, project_complexity)
        total_cost = cost(num_agents, days_needed)

        # Check constraints
        if days_needed > deadline_days:
            continue  # Too slow
        if total_cost > budget:
            continue  # Too expensive

        # Score = value delivered per dollar spent
        value = 1000 * project_complexity  # Assume $1000 value per complexity unit
        score = value / total_cost

        if score > best_score:
            best_score = score
            best_size = num_agents

    return {
        'optimal_size': best_size,
        'days': time_to_complete(best_size, project_complexity),
        'cost': cost(best_size, time_to_complete(best_size, project_complexity)),
        'value_per_dollar': best_score
    }
```

**Example: Inventory Management System**

- Project complexity: 200 agent-days
- Deadline: 14 days
- Budget: $15,000

```python
result = optimize_swarm_size(
    project_complexity=200,
    deadline_days=14,
    budget=15000
)

# Output:
# {
#   'optimal_size': 20,
#   'days': 13.2,
#   'cost': $10,450,
#   'value_per_dollar': 19.14
# }
```

Using 20 agents instead of 40 saves $4,550 while still meeting the deadline.

### Strategy 5: Progressive Swarm Scaling

Start small, scale up only if needed.

```python
def progressive_scaling(initial_size=10, max_size=50, evaluation_interval_days=2):
    """
    Start with small swarm, scale up based on progress.
    """
    swarm_size = initial_size
    day = 0

    while not project_complete():
        # Run swarm for evaluation interval
        run_swarm(swarm_size, days=evaluation_interval_days)
        day += evaluation_interval_days

        # Evaluate progress
        progress = measure_progress()
        target_progress = (day / total_estimated_days) * 100

        if progress < target_progress * 0.8:
            # Behind schedule: scale up
            new_size = min(swarm_size + 10, max_size)
            print(f"Day {day}: Behind schedule ({progress:.1f}% vs {target_progress:.1f}%). Scaling from {swarm_size} to {new_size} agents.")
            swarm_size = new_size

        elif progress > target_progress * 1.2:
            # Ahead of schedule: scale down
            new_size = max(swarm_size - 5, initial_size)
            print(f"Day {day}: Ahead of schedule ({progress:.1f}% vs {target_progress:.1f}%). Scaling from {swarm_size} to {new_size} agents.")
            swarm_size = new_size

        else:
            # On track: maintain size
            print(f"Day {day}: On track ({progress:.1f}% vs {target_progress:.1f}%). Maintaining {swarm_size} agents.")
```

**Example execution:**

```
Day 2: On track (15.3% vs 14.3%). Maintaining 10 agents.
Day 4: Behind schedule (24.1% vs 28.6%). Scaling from 10 to 20 agents.
Day 6: On track (44.7% vs 42.9%). Maintaining 20 agents.
Day 8: Ahead of schedule (65.2% vs 57.1%). Scaling from 20 to 15 agents.
Day 10: On track (74.8% vs 71.4%). Maintaining 15 agents.
Day 12: On track (89.3% vs 85.7%). Maintaining 15 agents.
Day 14: Complete (100%).
```

**Cost comparison:**

- Fixed 40 agents for 14 days: $25,200
- Fixed 20 agents for 14 days: $12,600
- Progressive scaling (average 15 agents): $9,450

Savings: $15,750 (62% reduction) compared to fixed 40-agent swarm.

## Budget Constraints and Hard Limits

Sometimes you have a hard budget limit. How do you ensure the swarm doesn't exceed it?

```python
class BudgetEnforcer:
    def __init__(self, total_budget, safety_margin=0.15):
        self.total_budget = total_budget
        self.safety_margin = safety_margin
        self.effective_budget = total_budget * (1 - safety_margin)
        self.spent = 0.0

    def check_action_allowed(self, estimated_cost):
        """
        Return True if action is within budget, False otherwise.
        """
        if self.spent + estimated_cost > self.effective_budget:
            return False
        return True

    def record_cost(self, actual_cost):
        """
        Record actual cost of an action.
        """
        self.spent += actual_cost

        # Warn if approaching budget limit
        if self.spent > self.effective_budget * 0.90:
            remaining = self.total_budget - self.spent
            print(f"WARNING: 90% of budget consumed. ${remaining:.2f} remaining.")

    def estimate_remaining_work(self, progress_percentage):
        """
        Estimate if remaining budget is sufficient to complete project.
        """
        if progress_percentage == 0:
            return True  # Can't estimate yet

        projected_total = self.spent / (progress_percentage / 100)
        projected_overage = projected_total - self.total_budget

        if projected_overage > 0:
            return False, f"Projected to exceed budget by ${projected_overage:.2f}"

        return True, f"On track. Projected total: ${projected_total:.2f}"
```

**Example: Mid-project budget check**

```python
enforcer = BudgetEnforcer(total_budget=15000, safety_margin=0.15)

# After 7 days of 14-day project
enforcer.spent = 7800
progress = 45  # 45% complete

sufficient, message = enforcer.estimate_remaining_work(progress)
print(message)

# Output: "Projected to exceed budget by $2,333. Projected total: $17,333"
```

**Response options:**

1. **Reduce swarm size**: From 30 agents to 20 agents (saves ~$1,300/week)
2. **Switch to cheaper models**: Use GPT-4 Turbo instead of GPT-4 (saves ~60%)
3. **Reduce scope**: Defer non-critical features to future sprint
4. **Increase budget**: Request additional $2,500 from stakeholders
5. **Optimize context**: More aggressive context pruning (saves ~30%)

## Real-World Example: SaaS Startup MVP

Let me share a concrete example that brings these concepts together.

**Scenario:**

Startup building a project management SaaS. Need MVP in 3 weeks. Budget: $8,000 for development.

**Initial plan:**
- 30 agents
- GPT-4 for everything
- 21 days
- Estimated cost: $18,900

Budget violation: $10,900 over budget.

**Optimization 1: Model mixing**

- Core features (30% of work): GPT-4 (10 agents)
- Standard features (50% of work): GPT-4 Turbo (15 agents)
- Simple features (20% of work): GPT-3.5 Turbo (5 agents)

New estimated cost: $9,470
Still $1,470 over budget.

**Optimization 2: Context window reduction**

Aggressive context pruning:
- Only include files directly related to current task
- Summarize files >300 lines
- Limit conversation history to last 3 exchanges

Estimated savings: 35% of LLM costs
New estimated cost: $6,890
Now $1,110 under budget! ✅

**Optimization 3: Caching**

Implement aggressive response caching:
- Cache code analysis results
- Cache common patterns
- Reuse test generation for similar structures

Estimated savings: Additional 25% of LLM costs
New estimated cost: $5,760
Total savings: $13,140 (70% reduction) ✅

**Final configuration:**
- 30 agents (10 GPT-4, 15 GPT-4 Turbo, 5 GPT-3.5 Turbo)
- Aggressive context optimization
- Response caching enabled
- 21 days
- Total cost: $5,760
- Under budget by: $2,240

**Actual results:**

Week 1: Spent $1,950 (on track)
Week 2: Spent $2,100 (on track)
Week 3: Spent $1,710 (ahead of schedule, completed on Day 19)

Final cost: $5,760
Final timeline: 19 days (2 days early)
Budget remaining: $2,240

The MVP launched successfully, under budget and ahead of schedule. The optimizations made it economically viable.

## Cost-Effectiveness Metrics

Beyond raw cost, measure cost-effectiveness:

```python
def calculate_cost_effectiveness(project):
    """
    Measure value delivered per dollar spent.
    """
    # Cost
    total_cost = project.total_spent

    # Value delivered (multiple dimensions)
    value_metrics = {
        'features_delivered': project.features_completed,
        'defect_rate': 1 - project.defect_rate,  # Lower defects = higher value
        'time_saved': project.estimated_days - project.actual_days,
        'quality_score': project.maintainability_index / 100
    }

    # Weighted value score
    value_score = (
        value_metrics['features_delivered'] * 0.4 +
        value_metrics['defect_rate'] * 0.2 +
        value_metrics['time_saved'] * 0.2 +
        value_metrics['quality_score'] * 0.2
    )

    # Cost-effectiveness = value per dollar
    cost_effectiveness = value_score / total_cost

    return {
        'total_cost': total_cost,
        'value_score': value_score,
        'cost_effectiveness': cost_effectiveness,
        'metrics': value_metrics
    }
```

**Example comparison:**

**Traditional development:**
- Cost: $30,000 (2 engineers × 3 weeks)
- Features delivered: 25
- Defect rate: 8%
- Time: 21 days (as estimated)
- Quality score: 82/100
- Value score: 25 × 0.4 + 0.92 × 0.2 + 0 × 0.2 + 0.82 × 0.2 = 10.348
- Cost-effectiveness: 10.348 / 30000 = 0.000345

**Swarm development:**
- Cost: $5,760
- Features delivered: 25
- Defect rate: 12%
- Time: 19 days (2 days early)
- Quality score: 76/100
- Value score: 25 × 0.4 + 0.88 × 0.2 + 2 × 0.2 + 0.76 × 0.2 = 10.728
- Cost-effectiveness: 10.728 / 5760 = 0.001862

Swarm is 5.4× more cost-effective despite slightly higher defect rate and lower quality score, because the speed advantage and lower cost more than compensate.

## Key Takeaways

1. **Swarm development has significant compute costs.** LLM API calls typically account for 60-70% of total cost. Be prepared for $1,000-$2,000/day burn rates for medium-sized swarms.

2. **Five optimization strategies:**
   - Model selection and mixing: Use expensive models only for complex tasks
   - Context window optimization: Minimize tokens sent to LLM without losing essential information
   - Caching and lazy evaluation: Don't recompute what you've already computed
   - Swarm size optimization: More agents ≠ better results due to coordination overhead
   - Progressive scaling: Start small, scale up only if needed

3. **Budget enforcement is critical.** Implement hard limits to prevent runaway costs. Monitor spending in real-time and project whether remaining budget is sufficient.

4. **Cost-effectiveness matters more than raw cost.** Spending $10,000 to save $50,000 in salary costs and deliver 2 weeks faster is excellent ROI. Measure value delivered per dollar spent.

5. **Practical savings are dramatic.** With proper optimization, costs can be reduced by 50-70% without significantly impacting quality or speed.

6. **Economics favor swarms for the right projects.** Time-critical projects, high-value features, or situations where speed is worth premium cost all favor swarm development. Routine maintenance work may not.

In the next part of the book, we'll explore practical implementation—how to actually build and deploy swarm-based development systems in your organization.
